{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f49deae2",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "Run cell labelled #main with the required parameters\n",
    "\n",
    "Each table is extracted into a folder with the following files:\n",
    "\n",
    "1. charts/ : contains images of charts in the workbook (using xlwings library)\n",
    "2. images/ : contains imaged embedded into the workbook (using openpyxl)\n",
    "3. sheetjson.json : json of all the data in the workbook, including details of:  \n",
    "a. Named items such as tables  \n",
    "b. Hyerlinks  \n",
    "c. Chart descriptions  \n",
    "d. Table metadata  \n",
    "e. Pivot table descriptions  \n",
    "f. Conditional formatting details (if any)  \n",
    "g. Data validation rules (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e64d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions - sheet json (formatting removal, hyperlinks, metadata, data validation)\n",
    "import json\n",
    "def remove_formatting(sheet_json):\n",
    "    \"\"\"\n",
    "    Remove all formatting from the sheet JSON, keeping only data and structure.\n",
    "    \"\"\"\n",
    "    # Remove 'meta' from overall structure\n",
    "    if 'meta' in sheet_json:\n",
    "        del sheet_json['meta']\n",
    "    \n",
    "    # Process each worksheet\n",
    "    for worksheet_name, worksheet_data in sheet_json.get('worksheets', {}).items():\n",
    "        \n",
    "        # Remove worksheet properties (contains formatting/display settings)\n",
    "        if 'worksheetProperties' in worksheet_data:\n",
    "            del worksheet_data['worksheetProperties']\n",
    "        \n",
    "        # Remove formatting from individual cells\n",
    "        if 'cells' in worksheet_data:\n",
    "            for cell_ref, cell_data in worksheet_data['cells'].items():\n",
    "                # Keep only the value, remove all Format information\n",
    "                if 'Format' in cell_data:\n",
    "                    del cell_data['Format']\n",
    "                \n",
    "                # Remove other formatting-related properties if they exist\n",
    "                formatting_keys = ['style', 'font', 'fill', 'border', 'alignment', \n",
    "                                 'number_format', 'protection']\n",
    "                for key in formatting_keys:\n",
    "                    if key in cell_data:\n",
    "                        del cell_data[key]\n",
    "        \n",
    "        #if cells are empty, remove them\n",
    "        empty_cells = [cell for cell, data in worksheet_data.get('cells', {}).items() if not data or 'value' not in data]\n",
    "        for cell in empty_cells:\n",
    "            del worksheet_data['cells'][cell]\n",
    "        \n",
    "        # Remove chart formatting but keep chart data structure\n",
    "        if 'charts' in worksheet_data:\n",
    "            for chart in worksheet_data['charts']:\n",
    "                # Remove visual/formatting properties from chart level\n",
    "                chart_formatting_keys = ['style', 'plotArea', 'chartArea']\n",
    "                for key in chart_formatting_keys:\n",
    "                    if key in chart:\n",
    "                        del chart[key]\n",
    "                \n",
    "                # Clean up legend - keep position and visibility, remove formatting\n",
    "                if 'legend' in chart and isinstance(chart['legend'], dict):\n",
    "                    legend = chart['legend']\n",
    "                    # Keep only essential properties\n",
    "                    essential_legend = {}\n",
    "                    if 'position' in legend:\n",
    "                        essential_legend['position'] = legend['position']\n",
    "                    if 'visible' in legend:\n",
    "                        essential_legend['visible'] = legend['visible']\n",
    "                    chart['legend'] = essential_legend\n",
    "                \n",
    "                # Clean up title - keep text and essential properties\n",
    "                if 'title' in chart and isinstance(chart['title'], dict):\n",
    "                    title = chart['title']\n",
    "                    essential_title = {}\n",
    "                    if 'text' in title:\n",
    "                        essential_title['text'] = title['text']\n",
    "                    if 'formula' in title:\n",
    "                        essential_title['formula'] = title['formula']\n",
    "                    chart['title'] = essential_title\n",
    "                \n",
    "                # Remove all formatting from axes\n",
    "                if 'axes' in chart:\n",
    "                    for axis_name, axis_data in chart['axes'].items():\n",
    "                        if isinstance(axis_data, dict):\n",
    "                            # Keep only essential axis properties, remove all formatting\n",
    "                            essential_axis = {}\n",
    "                            \n",
    "                            # Keep structural/functional properties\n",
    "                            functional_props = [\n",
    "                                'position', 'visible', 'numberFormat', 'minimum', 'maximum',\n",
    "                                'majorUnit', 'minorUnit', 'scaleType', 'categoryType'\n",
    "                            ]\n",
    "                            \n",
    "                            for prop in functional_props:\n",
    "                                if prop in axis_data:\n",
    "                                    essential_axis[prop] = axis_data[prop]\n",
    "                            \n",
    "                            chart['axes'][axis_name] = essential_axis\n",
    "                \n",
    "                # Clean up series - remove formatting but keep data\n",
    "                if 'series' in chart:\n",
    "                    for series in chart['series']:\n",
    "                        # Remove visual formatting from series\n",
    "                        series_formatting_keys = [\n",
    "                            'format', 'marker', 'line', 'fill', 'smooth', 'dataLabels',\n",
    "                            'trendline', 'errorBars', 'pictureOptions'\n",
    "                        ]\n",
    "                        for key in series_formatting_keys:\n",
    "                            if key in series:\n",
    "                                del series[key]\n",
    "                        \n",
    "                        # Keep only essential series data\n",
    "                        essential_series_props = [\n",
    "                            'idx', 'order', 'title', 'categories', 'values', \n",
    "                            'xValues', 'yValues', 'bubbleSize'\n",
    "                        ]\n",
    "                        \n",
    "                        # Create clean series dict\n",
    "                        clean_series = {}\n",
    "                        for prop in essential_series_props:\n",
    "                            if prop in series:\n",
    "                                clean_series[prop] = series[prop]\n",
    "                        \n",
    "                        # Update the series with clean version\n",
    "                        series.clear()\n",
    "                        series.update(clean_series)\n",
    "        \n",
    "        # Clean up named items (remove any formatting metadata)\n",
    "        if 'namedItems' in worksheet_data:\n",
    "            for named_item in worksheet_data['namedItems']:\n",
    "                if 'format' in named_item:\n",
    "                    del named_item['format']\n",
    "        \n",
    "        # Remove conditional formatting entirely\n",
    "        # if 'conditionalFormatting' in worksheet_data:\n",
    "            # del worksheet_data['conditionalFormatting']\n",
    "        \n",
    "        # Remove style-related properties from tables\n",
    "        if 'tables' in worksheet_data:\n",
    "            for table in worksheet_data['tables']:\n",
    "                table_formatting_keys = ['tableStyleInfo', 'format','predefinedTableStyle']\n",
    "                for key in table_formatting_keys:\n",
    "                    if key in table:\n",
    "                        del table[key]\n",
    "                table_formatting_keys_starters = ['show', 'highlight']\n",
    "                keys_to_del = []\n",
    "                for key in table_formatting_keys_starters:\n",
    "                    for table_key in table:\n",
    "                        if table_key.startswith(key):\n",
    "                            keys_to_del.append(table_key)\n",
    "                for key in keys_to_del:\n",
    "                    if key in table:\n",
    "                        del table[key]\n",
    "    \n",
    "    return sheet_json\n",
    "\n",
    "#add hyperlinks\n",
    "import openpyxl\n",
    "def extract_hyperlinks_from_excel(file_path):\n",
    "    \"\"\"\n",
    "    Extract all hyperlinks from an Excel workbook.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Excel file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with hyperlink information organized by worksheet\n",
    "    \"\"\"\n",
    "    \n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    hyperlinks_data = {}\n",
    "    \n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        worksheet = workbook[sheet_name]\n",
    "        sheet_hyperlinks = {}\n",
    "\n",
    "        #get range of rows and columns\n",
    "        max_row = worksheet.max_row\n",
    "        max_col = worksheet.max_column\n",
    "\n",
    "        \n",
    "        # Check each cell for hyperlinks\n",
    "        for row in range(1, max_row + 1):\n",
    "            for col in range(1, max_col + 1):\n",
    "                cell = worksheet.cell(row=row, column=col)\n",
    "                if not hasattr(cell.hyperlink, 'target'):\n",
    "                    continue\n",
    "                if cell.hyperlink is not None:\n",
    "                    cell_ref = cell.coordinate\n",
    "                    hyperlink_info = {\n",
    "                        'target': cell.hyperlink.target,\n",
    "                        # 'display': cell.hyperlink.display,\n",
    "                        # 'tooltip': cell.hyperlink.tooltip,\n",
    "                        # 'cell_value': cell.value,\n",
    "                        # 'location': cell.hyperlink.location if hasattr(cell.hyperlink, 'location') else None\n",
    "                    }\n",
    "                    sheet_hyperlinks[cell_ref] = hyperlink_info\n",
    "        \n",
    "        if sheet_hyperlinks:  # Only add if there are hyperlinks\n",
    "            hyperlinks_data[sheet_name] = sheet_hyperlinks\n",
    "        \n",
    "    \n",
    "    workbook.close()\n",
    "    print(hyperlinks_data)\n",
    "    return hyperlinks_data\n",
    "\n",
    "def add_hyperlinks_to_sheetjson(sheetjson, file_path):\n",
    "    \"\"\"\n",
    "    Add hyperlink information to the sheetjson structure.\n",
    "    \n",
    "    Args:\n",
    "        sheetjson: The existing sheetjson dictionary\n",
    "        file_path: Path to the Excel file containing hyperlinks\n",
    "        \n",
    "    Returns:\n",
    "        Updated sheetjson with hyperlinks added\n",
    "    \"\"\"\n",
    "    hyperlinks_data = extract_hyperlinks_from_excel(file_path)\n",
    "    # Add hyperlinks to each worksheet\n",
    "    for sheet_name, sheet_data in sheetjson.get('worksheets', {}).items():\n",
    "        if sheet_name in hyperlinks_data:\n",
    "            # Add hyperlinks to cells that have them\n",
    "            sheet_hyperlinks = hyperlinks_data[sheet_name]\n",
    "            \n",
    "            for cell_ref, hyperlink_info in sheet_hyperlinks.items():\n",
    "                # Check if the cell exists in sheetjson\n",
    "                if 'cells' not in sheet_data:\n",
    "                    sheet_data['cells'] = {}\n",
    "                \n",
    "                if cell_ref not in sheet_data['cells']:\n",
    "                    sheet_data['cells'][cell_ref] = {}\n",
    "                \n",
    "                # Add hyperlink information to the cell\n",
    "                sheet_data['cells'][cell_ref]['hyperlink'] = hyperlink_info\n",
    "            \n",
    "            # Also add a summary of hyperlinks at the worksheet level\n",
    "            sheet_data['hyperlinks_summary'] = {\n",
    "                'count': len(sheet_hyperlinks),\n",
    "                'cells_with_hyperlinks': list(sheet_hyperlinks.keys())\n",
    "            }\n",
    "    \n",
    "    return sheetjson\n",
    "\n",
    "def add_metadata_to_sheetjson(sheetjson, file_path):\n",
    "    \"\"\"\n",
    "    Add metadata information to the sheetjson structure.\n",
    "    \n",
    "    Args:\n",
    "        sheetjson: The existing sheetjson dictionary\n",
    "        file_path: Path to the Excel file containing metadata\n",
    "        \n",
    "    Returns:\n",
    "        Updated sheetjson with metadata added\n",
    "    \"\"\"\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    \n",
    "    # Extract metadata from the workbook properties\n",
    "    #convert properties to a dictionary\n",
    "    properties = workbook.properties\n",
    "    properties = {k: str(v) for k, v in properties.__dict__.items() if not k.startswith('_')}\n",
    "    \n",
    "    # Add metadata to the json as a new key\n",
    "    if 'meta' not in sheetjson:\n",
    "        sheetjson['meta'] = {}\n",
    "    \n",
    "    sheetjson['meta'] = properties\n",
    "    \n",
    "    return sheetjson\n",
    "\n",
    "import os\n",
    "def add_data_validation_to_sheetjson(sheetjson, file_path):\n",
    "    \"\"\"\n",
    "    Extract data validation rules from an Excel file.\n",
    "    \n",
    "    Args:\n",
    "        sheetjson: sheetjson for the excel file\n",
    "        file_path: Path to the Excel file\n",
    "    \"\"\"\n",
    "\n",
    "    wb = openpyxl.load_workbook(file_path)\n",
    "    sheet_rules = {}\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        sheet = wb[sheet_name]\n",
    "        data_validations = sheet.data_validations.dataValidation\n",
    "        \n",
    "        if data_validations:\n",
    "            # Create a dictionary to hold the data validation rules\n",
    "            validation_rules = {\n",
    "                'sheet_name': sheet_name,\n",
    "                'validations': []\n",
    "            }\n",
    "            \n",
    "            for dv in data_validations:\n",
    "                #rule should remove all None\n",
    "                rule = {k: str(v) for k, v in dv.__dict__.items() if v is not None}\n",
    "                validation_rules['validations'].append(rule)\n",
    "            \n",
    "            # Save the validation rules to a JSON file\n",
    "            # output_file = os.path.join(final_output_folder, f\"{sheet_name}_data_validation.json\")\n",
    "            # with open(output_file, 'w') as f:\n",
    "            #     json.dump(validation_rules, f, indent=4)\n",
    "            \n",
    "            # print(f\"Extracted data validation rules for sheet '{sheet_name}' to {output_file}\")\n",
    "    \n",
    "            sheet_rules[sheet_name] = validation_rules\n",
    "    \n",
    "    # Save all sheet rules to a single JSON file\n",
    "    for sheet_name in sheet_rules:\n",
    "        sheetjson['worksheets'][sheet_name]['data_validation'] = sheet_rules[sheet_name]\n",
    "    \n",
    "    return sheetjson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f37605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert workbook to sheetjson\n",
    "from sheetjson.core import SheetJson\n",
    "from sheetjson.util.minisheetjson import minimize_sheetjson_pruned_iterative\n",
    "import os\n",
    "\n",
    "def workbook_to_sheetjson(input_folder,input_filename,ouput_folder):\n",
    "    s2s = SheetJson('openpyxl')\n",
    "    input_file_path = os.path.join(input_folder,input_filename)\n",
    "    sheetjson = s2s.fromXLSX(input_file_path)\n",
    "\n",
    "    #we dont minimise as it deletes some stuff. need to try spreadsheet LLM's compressor\n",
    "    # sheetjson = minimize_sheetjson_pruned_iterative(sheetjson)\n",
    "\n",
    "    #dump raw\n",
    "    # with open('sheetjson.json', 'w') as f:\n",
    "    #     json.dump(sheetjson, f, indent=4)\n",
    "\n",
    "\n",
    "    sheetjson_no_formatting = remove_formatting(sheetjson)\n",
    "    # sheetjson_no_formatting = sheetjson\n",
    "\n",
    "    sheetjson_no_formatting = add_hyperlinks_to_sheetjson(sheetjson_no_formatting, input_file_path)\n",
    "\n",
    "    sheetjson_no_formatting = add_metadata_to_sheetjson(sheetjson_no_formatting, input_file_path)\n",
    "\n",
    "    sheetjson_no_formatting = add_data_validation_to_sheetjson(sheetjson_no_formatting,input_file_path)\n",
    "\n",
    "\n",
    "    #write the sheetjson to a file\n",
    "    # with open('sheetjson_no_formatting.json', 'w') as f:\n",
    "    #     json.dump(sheetjson_no_formatting, f, indent=4)\n",
    "\n",
    "    output_file_path = os.path.join(ouput_folder, input_filename.split('.')[0])\n",
    "    os.makedirs(output_file_path, exist_ok=True)\n",
    "    with open(os.path.join(output_file_path, 'sheetjson.json'), 'w') as f:\n",
    "        json.dump(sheetjson, f, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "#ingore below\n",
    "# for sheet_name, sheet_data in sheetjson.get(\"worksheets\", {}).items():\n",
    "#         sheet_metadata[sheet_name] = {\n",
    "#             'has_tables': len(sheet_data.get('tables', [])) > 0,\n",
    "#             'has_charts': len(sheet_data.get('charts', [])) > 0,\n",
    "#             'has_pivots': len(sheet_data.get('pivots', [])) > 0,\n",
    "#             'has_conditional_formatting': len(sheet_data.get('conditionalFormatting', [])) > 0,\n",
    "#             'table_names': [t.get('name') for t in sheet_data.get('tables', [])],\n",
    "#             'chart_count': len(sheet_data.get('charts', [])),\n",
    "#             'named_items': [ni.get('name') for ni in sheet_data.get('namedItems', [])]\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea4bb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract embedded images from the excel file\n",
    "import openpyxl\n",
    "from openpyxl.drawing.image import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image as PILImage\n",
    "import io \n",
    "def extract_images_from_excel(input_folder, input_file_name, output_folder):\n",
    "    \"\"\"\n",
    "    Extract all embedded images from an Excel workbook and save them to a folder.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Excel file\n",
    "        output_folder: Folder to save extracted images\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load the workbook\n",
    "    input_file_path = os.path.join(input_folder, input_file_name)\n",
    "    workbook = openpyxl.load_workbook(input_file_path)\n",
    "    \n",
    "    image_count = 0\n",
    "    extracted_images = []\n",
    "    \n",
    "    # Iterate through all worksheets\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        worksheet = workbook[sheet_name]\n",
    "        \n",
    "        # Check if the worksheet has any images\n",
    "        if hasattr(worksheet, '_images') and worksheet._images:\n",
    "            for img in worksheet._images:\n",
    "                try:\n",
    "                    # Get image data\n",
    "                    image_data = img._data()\n",
    "                    \n",
    "                    # Determine file extension based on image format\n",
    "                    if image_data.startswith(b'\\x89PNG'):\n",
    "                        ext = '.png'\n",
    "                    elif image_data.startswith(b'\\xff\\xd8'):\n",
    "                        ext = '.jpg'\n",
    "                    elif image_data.startswith(b'GIF'):\n",
    "                        ext = '.gif'\n",
    "                    elif image_data.startswith(b'BM'):\n",
    "                        ext = '.bmp'\n",
    "                    else:\n",
    "                        ext = '.png'  # Default to PNG\n",
    "                    \n",
    "                    # Create filename\n",
    "                    filename = f\"image{image_count + 1}{ext}\"\n",
    "                    filepath = os.path.join(output_folder, input_file_name.split('.')[0])\n",
    "                    os.makedirs(filepath, exist_ok=True)\n",
    "                    filepath = os.path.join(filepath, \"images\")\n",
    "                    #CREATE the folder if it does not exist\n",
    "                    os.makedirs(filepath, exist_ok=True)\n",
    "                    filepath = os.path.join(filepath, filename)\n",
    "                    \n",
    "                    # Save the image\n",
    "                    with open(filepath, 'wb') as f:\n",
    "                        f.write(image_data)\n",
    "                    \n",
    "                    image_info = {\n",
    "                        'sheet': sheet_name,\n",
    "                        'filename': filename,\n",
    "                        'filepath': filepath,\n",
    "                        'anchor': getattr(img, 'anchor', None)\n",
    "                    }\n",
    "                    \n",
    "                    extracted_images.append(image_info)\n",
    "                    image_count += 1\n",
    "                    \n",
    "                    print(f\"Extracted: {filename} from sheet '{sheet_name}'\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting image from sheet '{sheet_name}': {e}\")\n",
    "    \n",
    "    workbook.close()\n",
    "    \n",
    "    return extracted_images\n",
    "\n",
    "# Extract images from the Excel file\n",
    "# extract_images_from_excel(FILE_PATH, FILE_NAME, OUTPUT_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8657fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract chart images\n",
    "import xlwings as xw\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_chart_images(input_folder,input_filename, output_folder):\n",
    "    \"\"\"\n",
    "    Opens the specified workbook and returns the first chart object.\n",
    "    \"\"\"\n",
    "    app = xw.App(visible=False)\n",
    "    input_file_path = os.path.join(input_folder, input_filename)\n",
    "    wb  = app.books.open(input_file_path)\n",
    "    chart_output_dir = os.path.join(output_folder, input_filename.split('.')[0])\n",
    "    os.makedirs(chart_output_dir, exist_ok=True)\n",
    "    chart_output_dir = os.path.join(chart_output_dir, \"charts\")\n",
    "    os.makedirs(chart_output_dir, exist_ok=True)\n",
    "\n",
    "    for sheet_file in wb.sheets: \n",
    "        try:\n",
    "            \n",
    "            sht = wb.sheets[sheet_file.name]\n",
    "            # print(sht.charts)\n",
    "            i = 1\n",
    "            for chart in sht.charts:\n",
    "                # print(chart)\n",
    "                # print(chart.chart_type)\n",
    "                chart_filename = f\"chart{i}.pdf\"\n",
    "                output_path = os.path.join(chart_output_dir, chart_filename)\n",
    "                chart.to_pdf(output_path)\n",
    "                # chart.to_pdf(\"chart.pdf\")\n",
    "                print(f\"Exported chart {i} to {output_path}\")\n",
    "                i += 1\n",
    "        except Exception as e:  \n",
    "            print(e) \n",
    "            continue \n",
    "    \n",
    "    wb.close()\n",
    "    app.quit()\n",
    "\n",
    "# extract_chart_images(FILE_PATH,FILE_NAME,OUTPUT_FOLDER_PATH)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9801bdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Evaluation': {'A1': {'target': 'https://1drv.ms/f/s!Al-rjBLU5Po1gkTqI7P0h_jcqq_h?e=GSWTsV'}}}\n",
      "{'Project tracker': {'H2': {'target': 'https:/aeyush10.github.io'}}}\n",
      "Extracted: image1.png from sheet 'Project tracker'\n",
      "Exported chart 1 to spreadsheet_data_new\\template\\charts\\chart1.pdf\n",
      "Exported chart 2 to spreadsheet_data_new\\template\\charts\\chart2.pdf\n",
      "{'Project tracker': {'H2': {'target': 'https:/aeyush10.github.io'}}}\n",
      "Extracted: image1.png from sheet 'Project tracker'\n",
      "Exported chart 1 to spreadsheet_data_new\\template2\\charts\\chart1.pdf\n",
      "Exported chart 2 to spreadsheet_data_new\\template2\\charts\\chart2.pdf\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "\n",
    "INPUT_FOLDER = \"raw_spreadsheets\"\n",
    "OUTPUT_FOLDER = \"spreadsheet_data_new\"\n",
    "\n",
    "from pathlib import Path\n",
    "#iterate over input folder to get file names\n",
    "excel_files = list(Path(INPUT_FOLDER).glob(\"*.xlsx\")) + list(Path(INPUT_FOLDER).glob(\"*.xls\"))\n",
    "\n",
    "for file in excel_files:\n",
    "    file_name = str(file).split('\\\\')[-1]\n",
    "    # print(file_name)\n",
    "    workbook_to_sheetjson(INPUT_FOLDER,file_name,OUTPUT_FOLDER)\n",
    "    extract_images_from_excel(INPUT_FOLDER,file_name,OUTPUT_FOLDER)\n",
    "    extract_chart_images(INPUT_FOLDER,file_name,OUTPUT_FOLDER)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
